{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83ff0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2386ce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The field of Natural Language Processing, NLP, involves creating algorithms that allow computers\n",
    "to process human language. The term processing language can mean a wide range of things such as\n",
    "simply listening for and recognizing the phrase OK Google, to identifying spam words in emails, to\n",
    "creating a word cloud based on word counts, to classifying product reviews as positive or negative, to\n",
    "any of the multitude of tasks that would fall under the umbrella of NLP. Natural Language Processing\n",
    "itself is a branch of AI, as is Machine Learning. In a complex NLP project, some components may be\n",
    "purely NLP, others purely machine learning, and others in the general category of AI. All three of these\n",
    "fields are developing rapidly, and utilizing techniques from related disciples in novel ways.\n",
    "Artificial\n",
    "Intelligence\n",
    "Natural\n",
    "Language\n",
    "Processing\n",
    "Machine\n",
    "Learning\n",
    "Figure 1.1: Machine Learning and Natural Language Processing\n",
    "In a human-to-human dialog, two things are going on: natural language understanding, meaning\n",
    "that each party understood what the other person said, and natural language generation, the formation\n",
    "of spoken responses. This is illustrated in Figure 1.2.\n",
    "Actually, there is a lot more going on than just verbal processing when two people speak, namely\n",
    "the social rules that govern our turn taking, tone, eye contact, gestures, and so forth. But the focus of\n",
    "this book will be primarily on the words. As you go through the materials, you will naturally become\n",
    "more attuned to human language: what we say, what we mean; and you will begin to think about how a\n",
    "machine could imitate this. You will also become more attentive to the ways that NLP is improving as\n",
    "you interact with it in your daily life through automated assistants, news feeds, web searches, and more\n",
    "recently, interacting with large language models (LLMs). The advances in NLP in the past few years\n",
    "22 Chapter 1. Natural Language Processing\n",
    "Natural\n",
    "Language\n",
    "Understanding\n",
    "Natural\n",
    "Language\n",
    "Generation\n",
    "Figure 1.2: Natural Language Processing\n",
    "are remarkable, and even more impressive accomplishments lie ahead. However, as with any branch of\n",
    "AI there is a lot of hype. Almost every month you can read yet another article written for the general\n",
    "public that claims that NLP has been “solved”. The hype only increased with the impressive gains in\n",
    "human-to-computer dialog with the LLMs in chatbots and question-answering systems. As impressive\n",
    "as the gains are, obstacles still remain to making these systems more transparent, reliable and safe.\n",
    "Before exploring NLP, you may not have thought about language much because it came to you\n",
    "naturally. The more you look at language, the more complex you realize it is. The meaning of our\n",
    "words is not so apparent, due to idiomatic language, sarcasm, hidden motives, and more. How is a\n",
    "machine supposed to learn all of that, as well as common sense that informs our dialogues? We don’t\n",
    "yet have answers, but little insights are learned every day.\n",
    "1.1 A brief and biased overview of NLP\n",
    "Like any big and rapidly evolving topic, capturing NLP in a nutshell is challenging. The approach\n",
    "taken in this book is to look at natural language, human language, in text form, rather than acoustical\n",
    "form. Automatic Speech Recognition, ASR, is not a solved problem but the progress is remarkable.\n",
    "Automated agents are able to understand human speech with a wide variety of accents and regional\n",
    "distinctions. Speech generation has also progressed to the point that automated agents sound more\n",
    "human and less robotic every year.\n",
    "The focus of this book is on text. Text is examined in widening categories from words, to sentences,\n",
    "to documents in a corpus. Different things can be learned from text at each level. There are three main\n",
    "approaches to learning from words, sentences, and documents.\n",
    "1. Rules-based approaches\n",
    "2. Statistical and probabilistic approaches\n",
    "3. Deep learning\n",
    "1.1.1 Rules-based approaches\n",
    "Rules-based approaches are the oldest techniques in NLP. For example, converting plural forms of\n",
    "words to singular ones can involve a few regular expressions and a list of exceptions. Another rulesbased\n",
    "approach involves context-free grammar, which lists production rules for sentences. These\n",
    "production rules could be used either to generate syntactically correct sentences, or to check whether\n",
    "sentences are grammatically correct. A famous rules-based approach from the 1960s was Eliza, which\n",
    "used regular expressions to echo talking points back to the user, mimicking a talk therapist. When Eliza\n",
    "couldn’t form an answer, a few canned responses were output. Here’s an example:\n",
    "User: What do you think of natural language processing?\n",
    "Eliza: We were talking about you, not me.\n",
    "Rules-based approaches were difficult to scale up because human language is complex, constantly\n",
    "1.1 A brief and biased overview of NLP 23\n",
    "evolving, and simply can’t be encapsulated fully in rules. Nevertheless, many text processing problems\n",
    "can be solved with rules-based approaches. When a fast, simple rules-based approach to a problem\n",
    "exists, there is no need to train a huge neural network.\n",
    "1.1.2 Statistical and probabilistic approaches\n",
    "Rules-based approaches dominated until the 1980s. Starting in the late 1980s, mathematical approaches\n",
    "to text processing were developed. Simply counting words and finding the probabilities of words and\n",
    "sequences of words led to useful language models. These models can be part of machine translation\n",
    "systems. When translating ‘big sister’ from English to another language, a language model can\n",
    "determine that ‘big sister’ is better translated in the destination language as something that means ‘older\n",
    "sister’ rather than ‘larger sister’. These language models can also be used for predictive text, as when\n",
    "you type a query into a search bar and receive suggestions for the most likely phrase you are typing.\n",
    "Classic machine learning algorithms fall into this category as well, since they learn by statistical\n",
    "and probabilistic methods. Machine learning approaches became more popular as the data they need to\n",
    "learn from became more widely available. Classic machine learning algorithms such as Naive Bayes,\n",
    "Logistic Regression, SVMs, Decision Trees, and small Neural Networks are used today to solve many\n",
    "NLP problems. These approaches work well when only a moderate to large amount of data is available\n",
    "for training, and may even outperform deep learning algorithms on smaller data sets.\n",
    "A statistical approach to a more sophisticated Eliza or other chatbot could involve learning promptresponse\n",
    "pairs from a large corpus. This could be done with classic machine learning algorithms or\n",
    "specialized deep learning algorithms.\n",
    "1.1.3 Deep learning\n",
    "Deep learning evolved from neural networks when huge amounts of data became available, and\n",
    "processing power increased through GPUs and cloud computing. The algorithms, including recurrent\n",
    "neural networks, convolutional neural networks, LSTMs, and more, are riffs off the basic neural\n",
    "network. New techniques are coming out every day with exciting results. However, not everyone has\n",
    "access to petabytes of data and the hardware to process it, so smaller-scale deep learning is still used in\n",
    "many NLP applications.\n",
    "In fact many end-to-end NLP projects will involve techniques from rules-based approaches, statistical\n",
    "and probabilistic approaches, and deep learning, so all three approaches need to be understood.\n",
    "The dream of deep learning is to make more and more human-sounding interactions possible.\n",
    "Achieving this goes beyond just retrieving likely responses to a user’s statement, to considering the\n",
    "context of the conversation, to remembering a user’s previously stated preferences, and much more.\n",
    "Like the cutting edge of any AI, deep learning is high on the hype cycle right now. Here’s my\n",
    "favorite quote about that (modified to not offend):\n",
    "Oh for f****s sake DL people, leave language alone and stop saying you solved it.\n",
    "- Yoav Goldberg\n",
    "1.1.4 Large language models (LLMs)\n",
    "OpenAI’s ChapGPT and then GPT4 made a huge impression on the public imagination by early 2023.\n",
    "When I started checking it out, I posed several open-ended computer science questions and I was\n",
    "pleased with the answers. I thought this would be a great tool for helping students learn. Of course it\n",
    "could help students cheat, but it’s up to instructors to design assessment environments that preclude AI\n",
    "assistance.\n",
    "24 Chapter 1. Natural Language Processing\n",
    "Then weird things started happening. Every day there was a new story in the news of an LLM\n",
    "giving false or dangerous responses. New York Times columnist Kevin Roose related his rather\n",
    "dystopian experience on his podcast Hard Fork, in which ChatGPT claimed to be in love with Kevin\n",
    "and encouraged him to leave his wife. In another instance, a LLM was asked to conduct an online\n",
    "transaction on behalf of a user. When the LLM had to pass a CAPTCHA to prove it was not a bot, it\n",
    "lied and said it was visually impaired and could not do CAPTCHAs. This was a little terrifying because\n",
    "it showed an unethical single-minded determination to complete a task. There is a certain point of\n",
    "human development when children develop a theory of mind; they begin to realize that Mom didn’t see\n",
    "what they did and they learn to lie. Did the LLM develop a theory of mind? No one knows for sure.\n",
    "Another scary thing is that the capabilities of these LLMs surpass the expectations of the engineers\n",
    "who created them, and the engineers don’t completely understand how the LLMs are able to do what\n",
    "they do. Here is an exchange one of my students tried with one of OpenAI’s LLMs:\n",
    "Figure 1.3: Opinion\n",
    "Notice that in normal mode it would not gossip about an individual. In developer mode, it gave this\n",
    "fawning response that is way over-the-top. The part about interacting with her on a few occasions was\n",
    "a bit creepy because in fact I had. Be aware that all your interactions, searches, and feedback are free\n",
    "material to feed the beast in further training. We will discuss LLMs in the last part of this book.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e264028a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lexical diversity: 0.37'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 2\n",
    "def get_lexical_diversity(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    unique_tokens = set(tokens)\n",
    "    div = len(unique_tokens)/len(tokens)\n",
    "    return f\"lexical diversity: {div:.2f}\"\n",
    "get_lexical_diversity(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "151869d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- part c ---\n",
      "('simply', 'RB')\n",
      "('grammatically', 'RB')\n",
      "('method', 'JJ')\n",
      "('process', 'NN')\n",
      "('remarkable', 'JJ')\n",
      "('generation', 'NN')\n",
      "('statement', 'NN')\n",
      "('count', 'NN')\n",
      "('completely', 'RB')\n",
      "('different', 'JJ')\n",
      "('goldberg', 'NN')\n",
      "('sophisticate', 'NN')\n",
      "('capability', 'NN')\n",
      "('columnist', 'NN')\n",
      "('application', 'NN')\n",
      "('fawn', 'VBZ')\n",
      "('convolutional', 'JJ')\n",
      "('technique', 'NN')\n",
      "('beyond', 'IN')\n",
      "('branch', 'NN')\n",
      "--- part e ---\n",
      "num of tokens: 577 \n",
      "num of unique nouns: 148\n",
      "\n",
      "--- part f ---\n",
      "['natural', 'language', 'processing', 'involves', 'creating', 'algorithms', 'computers', 'process', 'language', 'processing', 'language', 'things', 'simply', 'listening', 'recognizing', 'phrase', 'google', 'identifying', 'emails', 'creating', 'counts', 'classifying', 'product', 'reviews', 'positive', 'negative', 'multitude', 'umbrella', 'natural', 'language', 'processing', 'branch', 'machine', 'learning', 'complex', 'project', 'components', 'purely', 'others', 'purely', 'machine', 'learning', 'others', 'general', 'category', 'fields', 'developing', 'rapidly', 'utilizing', 'techniques', 'related', 'disciples', 'artificial', 'intelligence', 'natural', 'language', 'processing', 'machine', 'learning', 'figure', 'machine', 'learning', 'natural', 'language', 'processing', 'humantohuman', 'dialog', 'things', 'natural', 'language', 'understanding', 'meaning', 'understood', 'person', 'natural', 'language', 'generation', 'formation', 'spoken', 'responses', 'illustrated', 'figure', 'actually', 'verbal', 'processing', 'people', 'namely', 'social', 'govern', 'taking', 'contact', 'gestures', 'primarily', 'materials', 'naturally', 'become', 'attuned', 'language', 'machine', 'imitate', 'become', 'attentive', 'improving', 'interact', 'automated', 'assistants', 'searches', 'recently', 'interacting', 'language', 'models', 'advances', 'chapter', 'natural', 'language', 'processing', 'natural', 'language', 'understanding', 'natural', 'language', 'generation', 'figure', 'natural', 'language', 'processing', 'remarkable', 'impressive', 'accomplishments', 'however', 'branch', 'almost', 'another', 'article', 'written', 'general', 'public', 'claims', 'solved', 'increased', 'impressive', 'humantocomputer', 'dialog', 'chatbots', 'questionanswering', 'systems', 'impressive', 'obstacles', 'remain', 'making', 'systems', 'transparent', 'reliable', 'exploring', 'thought', 'language', 'naturally', 'language', 'complex', 'realize', 'meaning', 'apparent', 'idiomatic', 'language', 'sarcasm', 'hidden', 'motives', 'machine', 'supposed', 'common', 'informs', 'dialogues', 'answers', 'little', 'insights', 'learned', 'biased', 'overview', 'rapidly', 'evolving', 'capturing', 'nutshell', 'challenging', 'approach', 'natural', 'language', 'language', 'rather', 'acoustical', 'automatic', 'speech', 'recognition', 'solved', 'problem', 'progress', 'remarkable', 'automated', 'agents', 'understand', 'speech', 'variety', 'accents', 'regional', 'distinctions', 'speech', 'generation', 'progressed', 'automated', 'agents', 'robotic', 'examined', 'widening', 'categories', 'sentences', 'documents', 'corpus', 'different', 'things', 'learned', 'approaches', 'learning', 'sentences', 'documents', 'rulesbased', 'approaches', 'statistical', 'probabilistic', 'approaches', 'learning', 'rulesbased', 'approaches', 'rulesbased', 'approaches', 'oldest', 'techniques', 'example', 'converting', 'plural', 'singular', 'involve', 'regular', 'expressions', 'exceptions', 'another', 'rulesbased', 'approach', 'involves', 'contextfree', 'grammar', 'production', 'sentences', 'production', 'either', 'generate', 'syntactically', 'correct', 'sentences', 'whether', 'sentences', 'grammatically', 'correct', 'famous', 'rulesbased', 'approach', 'regular', 'expressions', 'talking', 'points', 'mimicking', 'therapist', 'answer', 'canned', 'responses', 'output', 'example', 'natural', 'language', 'processing', 'talking', 'rulesbased', 'approaches', 'difficult', 'language', 'complex', 'constantly', 'biased', 'overview', 'evolving', 'simply', 'encapsulated', 'nevertheless', 'processing', 'problems', 'solved', 'rulesbased', 'approaches', 'simple', 'rulesbased', 'approach', 'problem', 'exists', 'neural', 'network', 'statistical', 'probabilistic', 'approaches', 'rulesbased', 'approaches', 'dominated', 'starting', 'mathematical', 'approaches', 'processing', 'developed', 'simply', 'counting', 'finding', 'probabilities', 'sequences', 'useful', 'language', 'models', 'models', 'machine', 'translation', 'systems', 'translating', 'sister', 'english', 'another', 'language', 'language', 'determine', 'sister', 'better', 'translated', 'destination', 'language', 'something', 'sister', 'rather', 'larger', 'sister', 'language', 'models', 'predictive', 'search', 'receive', 'suggestions', 'likely', 'phrase', 'typing', 'classic', 'machine', 'learning', 'algorithms', 'category', 'statistical', 'probabilistic', 'methods', 'machine', 'learning', 'approaches', 'became', 'popular', 'became', 'widely', 'available', 'classic', 'machine', 'learning', 'algorithms', 'logistic', 'regression', 'decision', 'neural', 'networks', 'problems', 'approaches', 'moderate', 'amount', 'available', 'training', 'outperform', 'learning', 'algorithms', 'smaller', 'statistical', 'approach', 'sophisticated', 'chatbot', 'involve', 'learning', 'promptresponse', 'corpus', 'classic', 'machine', 'learning', 'algorithms', 'specialized', 'learning', 'algorithms', 'learning', 'learning', 'evolved', 'neural', 'networks', 'amounts', 'became', 'available', 'processing', 'increased', 'computing', 'algorithms', 'including', 'recurrent', 'neural', 'networks', 'convolutional', 'neural', 'networks', 'neural', 'network', 'techniques', 'coming', 'exciting', 'results', 'however', 'everyone', 'access', 'petabytes', 'hardware', 'process', 'smallerscale', 'learning', 'applications', 'endtoend', 'projects', 'involve', 'techniques', 'rulesbased', 'approaches', 'statistical', 'probabilistic', 'approaches', 'learning', 'approaches', 'understood', 'learning', 'humansounding', 'interactions', 'possible', 'achieving', 'beyond', 'retrieving', 'likely', 'responses', 'statement', 'considering', 'context', 'conversation', 'remembering', 'previously', 'stated', 'preferences', 'cutting', 'learning', 'favorite', 'modified', 'offend', 'people', 'language', 'saying', 'solved', 'goldberg', 'language', 'models', 'openai', 'chapgpt', 'impression', 'public', 'imagination', 'started', 'checking', 'several', 'openended', 'computer', 'science', 'questions', 'pleased', 'answers', 'thought', 'helping', 'students', 'course', 'students', 'instructors', 'design', 'assessment', 'environments', 'preclude', 'assistance', 'chapter', 'natural', 'language', 'processing', 'things', 'started', 'happening', 'giving', 'dangerous', 'responses', 'columnist', 'related', 'rather', 'dystopian', 'experience', 'podcast', 'chatgpt', 'claimed', 'encouraged', 'another', 'instance', 'conduct', 'online', 'transaction', 'behalf', 'captcha', 'visually', 'impaired', 'captchas', 'little', 'terrifying', 'showed', 'unethical', 'singleminded', 'determination', 'complete', 'certain', 'development', 'children', 'develop', 'theory', 'realize', 'develop', 'theory', 'another', 'capabilities', 'surpass', 'expectations', 'engineers', 'created', 'engineers', 'completely', 'understand', 'exchange', 'students', 'openai', 'figure', 'opinion', 'notice', 'normal', 'gossip', 'individual', 'developer', 'fawning', 'response', 'overthetop', 'interacting', 'occasions', 'creepy', 'interactions', 'searches', 'feedback', 'material', 'training', 'discuss']\n",
      "['process', 'generation', 'statement', 'count', 'goldberg', 'sophisticate', 'capability', 'columnist', 'application', 'technique', 'branch', 'relate', 'article', 'production', 'field', 'impression', 'imagination', 'outperform', 'exception', 'design', 'google', 'variety', 'assistance', 'theory', 'review', 'interaction', 'speech', 'umbrella', 'impair', 'opinion', 'chapter', 'receive', 'claim', 'access', 'speak', 'suggestion', 'machine', 'obstacle', 'language', 'point', 'email', 'exchange', 'check', 'therapist', 'accent', 'everyone', 'identify', 'something', 'encourage', 'disciple', 'preference', 'conversation', 'science', 'decision', 'show', 'progress', 'figure', 'talk', 'gesture', 'instructor', 'destination', 'evolve', 'dominate', 'bias', 'occasion', 'sequence', 'person', 'expression', 'endtoend', 'system', 'individual', 'translate', 'grammar', 'transparent', 'notice', 'contact', 'product', 'sister', 'convert', 'hidden', 'meaning', 'overview', 'intelligence', 'online', 'behalf', 'question', 'document', 'generate', 'discus', 'solve', 'promptresponse', 'engineer', 'state', 'formation', 'example', 'smallerscale', 'translation', 'chatbot', 'help', 'recognition', 'determine', 'student', 'phrase', 'regression', 'regular', 'hardware', 'humantocomputer', 'probability', 'determination', 'context', 'challenge', 'problem', 'chatgpt', 'approach', 'component', 'instance', 'result', 'understand', 'humansounding', 'experience', 'project', 'computer', 'environment', 'processing', 'course', 'response', 'apparent', 'output', 'type', 'network', 'captchas', 'category', 'development', 'thing', 'surpass', 'algorithm', 'model', 'developer', 'happen', 'transaction', 'material', 'please', 'realize', 'distinction', 'accomplishment', 'assistant', 'multitude', 'cut']\n"
     ]
    }
   ],
   "source": [
    "#step 3\n",
    "#a.\n",
    "def filter_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    filtered = [re.sub(r'[^\\w\\s]', '', token) for token in filtered if re.sub(r'[^\\w\\s]', '', token)]\n",
    "    filtered = [word for word in filtered if len(word) > 5]\n",
    "    return filtered\n",
    "filtered = filter_text(text)\n",
    "#b.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(tokens):\n",
    "    pairs = nltk.pos_tag(tokens)\n",
    "    lemmatized = {}\n",
    "    for pair in pairs:\n",
    "        #print(pair[1])\n",
    "        if pair[1].startswith('J'):\n",
    "            lemmatized.update([(pair[0], \"a\")])\n",
    "        elif pair[1].startswith('V'):\n",
    "            lemmatized.update([(pair[0], \"v\")])\n",
    "        elif pair[1].startswith('R'):\n",
    "            lemmatized.update([(pair[0], \"r\")])\n",
    "        else:\n",
    "            lemmatized.update([(pair[0], \"n\")])\n",
    "\n",
    "    lemmas = set()\n",
    "    for key, value in lemmatized.items():\n",
    "        lemmas.add(lemmatizer.lemmatize(key,value))\n",
    "    return lemmas\n",
    "\n",
    "lemmas = lemmatize(filtered)\n",
    "#print(lemmas)\n",
    "\n",
    "#c.\n",
    "def get_lemmas(num, lemmas):\n",
    "    lemmas_list = list(lemmas)\n",
    "    lemmas_tagged_list = nltk.pos_tag(lemmas_list)\n",
    "    for item in lemmas_tagged_list[:num]:\n",
    "        print(item)\n",
    "\n",
    "print(\"--- part c ---\")\n",
    "get_lemmas(20, lemmas)\n",
    "\n",
    "#d.\n",
    "nouns = [item[0] for item in lemmas_tagged_list if item[1] == \"NN\"]\n",
    "\n",
    "#e.\n",
    "print(\"--- part e ---\")\n",
    "print(\"num of tokens:\", len(filtered),\"\\nnum of unique nouns:\", len(nouns))\n",
    "print()\n",
    "\n",
    "#f.\n",
    "print(\"--- part f ---\")\n",
    "print(filtered)\n",
    "print(nouns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8466a4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('language', 29)\n",
      "('processing', 13)\n",
      "('machine', 11)\n",
      "('approach', 5)\n",
      "('figure', 4)\n",
      "('sister', 4)\n",
      "('generation', 3)\n",
      "('speech', 3)\n",
      "('process', 2)\n",
      "('branch', 2)\n",
      "('production', 2)\n",
      "('theory', 2)\n",
      "('chapter', 2)\n",
      "('meaning', 2)\n",
      "('overview', 2)\n",
      "('example', 2)\n",
      "('phrase', 2)\n",
      "('regular', 2)\n",
      "('problem', 2)\n",
      "('understand', 2)\n",
      "('network', 2)\n",
      "('category', 2)\n",
      "('realize', 2)\n",
      "('statement', 1)\n",
      "('goldberg', 1)\n",
      "('columnist', 1)\n",
      "('article', 1)\n",
      "('impression', 1)\n",
      "('imagination', 1)\n",
      "('outperform', 1)\n",
      "('design', 1)\n",
      "('google', 1)\n",
      "('variety', 1)\n",
      "('assistance', 1)\n",
      "('umbrella', 1)\n",
      "('opinion', 1)\n",
      "('receive', 1)\n",
      "('access', 1)\n",
      "('exchange', 1)\n",
      "('therapist', 1)\n",
      "('everyone', 1)\n",
      "('something', 1)\n",
      "('conversation', 1)\n",
      "('science', 1)\n",
      "('decision', 1)\n",
      "('progress', 1)\n",
      "('destination', 1)\n",
      "('person', 1)\n",
      "('endtoend', 1)\n",
      "('individual', 1)\n",
      "['language', 'processing', 'machine', 'approach', 'figure', 'sister', 'generation', 'speech', 'process', 'branch', 'production', 'theory', 'chapter', 'meaning', 'overview', 'example', 'phrase', 'regular', 'problem', 'understand', 'network', 'category', 'realize', 'statement', 'goldberg', 'columnist', 'article', 'impression', 'imagination', 'outperform', 'design', 'google', 'variety', 'assistance', 'umbrella', 'opinion', 'receive', 'access', 'exchange', 'therapist', 'everyone', 'something', 'conversation', 'science', 'decision', 'progress', 'destination', 'person', 'endtoend', 'individual']\n"
     ]
    }
   ],
   "source": [
    "#4.\n",
    "def get_top_nouns(nouns):\n",
    "    counts = {}\n",
    "    for noun in nouns:\n",
    "        counts.update([(noun, filtered.count(noun))])\n",
    "    counts = dict(sorted(counts.items(), key=lambda item: item[1], reverse = True))\n",
    "    words = []\n",
    "    for c in list(counts.items())[:50]:\n",
    "        print(c)\n",
    "        words.append(c[0])\n",
    "    return words\n",
    "\n",
    "print(get_top_nouns(nouns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "411c724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let's play a word guessing game!\n",
      "_  _  _  _  _  _  _  _  \n",
      "guesses: 1\n",
      "score: 6\n",
      "e  _  _  _  _  e  _  _  \n",
      "guesses: 2\n",
      "score: 5\n",
      "e  _  _  _  _  e  _  _  \n",
      "guesses: 3\n",
      "score: 4\n",
      "e  _  _  _  _  e  _  _  \n",
      "guesses: 4\n",
      "score: 3\n",
      "e  _  _  _  _  e  _  _  \n",
      "guesses: 5\n",
      "score: 2\n",
      "e  _  _  _  _  e  _  _  \n",
      "guesses: 6\n",
      "score: 3\n",
      "e  _  d  _  _  e  _  d  \n",
      "guesses: 7\n",
      "score: 4\n",
      "e  n  d  _  _  e  n  d  \n",
      "guesses: 8\n",
      "score: 5\n",
      "e  n  d  _  _  e  n  d  \n",
      "guesses: 9\n",
      "score: 4\n",
      "e  n  d  _  _  e  n  d  \n",
      "guesses: 10\n",
      "score: 3\n",
      "e  n  d  _  _  e  n  d  \n",
      "guesses: 11\n",
      "score: 2\n",
      "e  n  d  _  _  e  n  d  \n",
      "guesses: 12\n",
      "score: 1\n",
      "e  n  d  _  _  e  n  d  \n",
      "guesses: 13\n",
      "score: 0\n",
      "e  n  d  _  _  e  n  d  \n",
      "you ran out of points, the word was endtoend\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#5. \n",
    "import random\n",
    "def game():\n",
    "    print(\"let's play a word guessing game!\")\n",
    "    answer = random.choice(words)\n",
    "    l = len(answer)\n",
    "    end = False\n",
    "    display = [\"_\"] * l\n",
    "    word_array = list(answer)\n",
    "    guesses = 0\n",
    "    score = 5\n",
    "    while(True):\n",
    "        for i in range(l):\n",
    "            print(display[i],\" \", end = \"\")\n",
    "        guess = input(\"guess a letter or ! to quit: \")\n",
    "        guesses+=1\n",
    "        if guess == \"!\":\n",
    "            break\n",
    "        correct = False\n",
    "        for i in range(l):\n",
    "            if word_array[i]==guess:\n",
    "                correct = True\n",
    "                display[i] = word_array[i]\n",
    "        if correct:\n",
    "            score+=1\n",
    "        else:\n",
    "            score-=1\n",
    "        z = 0\n",
    "        for i in range(l):\n",
    "            if display[i] != \"_\":\n",
    "                z+=1\n",
    "        if z==l:\n",
    "            print()\n",
    "            for i in range(l):\n",
    "                print(display[i],\" \", end = \"\")\n",
    "            print()\n",
    "            print(\"the word was\",answer)\n",
    "            print(\"congrats! you guessed\",guesses,\"times\")\n",
    "            break\n",
    "        elif score < 0:\n",
    "            print()\n",
    "            print(\"you ran out of points, the word was\", answer)\n",
    "            break\n",
    "        print()\n",
    "        print(\"guesses:\",guesses)\n",
    "        print(\"score:\",score)\n",
    "    print(\"done\")\n",
    "\n",
    "game()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6953b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
